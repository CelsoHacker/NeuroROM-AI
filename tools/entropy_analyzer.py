#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ENTROPY ANALYZER - Raio-X de ROMs atrav√©s de An√°lise de Entropia
================================================================================
Cria um mapa de calor da ROM para identificar:
- Texto/Tabelas (entropia baixa/m√©dia)
- C√≥digo execut√°vel (entropia m√©dia/alta)
- Dados comprimidos (entropia muito alta)
- Padding/zeros (entropia muito baixa)

Caracter√≠sticas:
- Processamento em blocos configur√°vel (256B, 512B, 1KB, etc)
- C√°lculo vetorizado com NumPy (extremamente r√°pido)
- Classifica√ß√£o autom√°tica de regi√µes
- Exporta√ß√£o de mapas visuais para interface

Performance:
- 4MB em < 0.5 segundos
- Blocos de 256 bytes: ~16K blocos processados instantaneamente
================================================================================
"""

import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import json


class BlockType(Enum):
    """Tipos de blocos identificados por entropia"""
    EMPTY = 0           # Entropia < 1.0 - Zeros/Padding
    VERY_LOW = 1        # 1.0 <= entropia < 2.0 - Dados repetitivos
    LOW = 2             # 2.0 <= entropia < 3.0 - Estruturas simples
    TEXT = 3            # 3.0 <= entropia < 4.0 - Texto ASCII/tabelas
    MIXED_TEXT = 4      # 4.0 <= entropia < 5.0 - Texto misto/dados
    CODE = 5            # 5.0 <= entropia < 6.0 - C√≥digo execut√°vel
    MIXED_DATA = 6      # 6.0 <= entropia < 7.0 - Dados mistos
    HIGH = 7            # 7.0 <= entropia < 7.5 - Dados complexos
    COMPRESSED = 8      # entropia >= 7.5 - Comprimido/encriptado

    def get_color(self) -> str:
        """Retorna cor para visualiza√ß√£o"""
        colors = {
            BlockType.EMPTY: "#1a1a1a",        # Preto
            BlockType.VERY_LOW: "#2d2d2d",     # Cinza escuro
            BlockType.LOW: "#4a4a4a",          # Cinza
            BlockType.TEXT: "#4CAF50",         # Verde (ALVO!)
            BlockType.MIXED_TEXT: "#8BC34A",   # Verde claro
            BlockType.CODE: "#FFC107",         # Amarelo
            BlockType.MIXED_DATA: "#FF9800",   # Laranja
            BlockType.HIGH: "#FF5722",         # Laranja escuro
            BlockType.COMPRESSED: "#F44336",   # Vermelho (PERIGO!)
        }
        return colors.get(self, "#666666")

    def get_description(self) -> str:
        """Retorna descri√ß√£o leg√≠vel"""
        descriptions = {
            BlockType.EMPTY: "Vazio/Padding",
            BlockType.VERY_LOW: "Dados Repetitivos",
            BlockType.LOW: "Estruturas Simples",
            BlockType.TEXT: "Texto/Tabelas",
            BlockType.MIXED_TEXT: "Texto Misto",
            BlockType.CODE: "C√≥digo Execut√°vel",
            BlockType.MIXED_DATA: "Dados Mistos",
            BlockType.HIGH: "Dados Complexos",
            BlockType.COMPRESSED: "Comprimido/Encriptado",
        }
        return descriptions.get(self, "Desconhecido")


@dataclass
class EntropyBlock:
    """Bloco analisado"""
    offset: int              # Offset inicial do bloco
    size: int                # Tamanho do bloco
    entropy: float           # Valor de entropia (0-8)
    block_type: BlockType    # Tipo classificado
    byte_distribution: Dict[int, int]  # Distribui√ß√£o de bytes

    def __repr__(self) -> str:
        return f"<Block @0x{self.offset:X} entropy={self.entropy:.2f} type={self.block_type.name}>"


@dataclass
class EntropyRegion:
    """Regi√£o cont√≠gua do mesmo tipo"""
    start_offset: int
    end_offset: int
    block_type: BlockType
    block_count: int
    avg_entropy: float

    @property
    def size(self) -> int:
        return self.end_offset - self.start_offset

    def __repr__(self) -> str:
        return (f"<Region 0x{self.start_offset:X}-0x{self.end_offset:X} "
                f"type={self.block_type.name} blocks={self.block_count}>")


class EntropyAnalyzer:
    """
    Analisador de entropia de alta performance para ROMs

    Usa entropia de Shannon para classificar regi√µes da ROM.
    Processamento vetorizado com NumPy para performance extrema.
    """

    def __init__(
        self,
        rom_path: str,
        block_size: int = 256,
        verbose: bool = False
    ):
        """
        Args:
            rom_path: Caminho para o arquivo ROM
            block_size: Tamanho dos blocos em bytes (256, 512, 1024, etc)
            verbose: Se True, imprime informa√ß√µes de debug
        """
        self.rom_path = Path(rom_path)
        self.block_size = block_size
        self.verbose = verbose

        # Carrega ROM
        if not self.rom_path.exists():
            raise FileNotFoundError(f"ROM n√£o encontrada: {rom_path}")

        self.rom_data = np.fromfile(self.rom_path, dtype=np.uint8)
        self.rom_size = len(self.rom_data)

        # Calcula n√∫mero de blocos
        self.num_blocks = (self.rom_size + block_size - 1) // block_size

        # Cache de resultados
        self.blocks: List[EntropyBlock] = []
        self.entropy_map: Optional[np.ndarray] = None
        self.type_map: Optional[np.ndarray] = None

        if self.verbose:
            print(f"[INFO] ROM carregada: {self.rom_path.name}")
            print(f"[INFO] Tamanho: {self.rom_size:,} bytes ({self.rom_size / 1024 / 1024:.2f} MB)")
            print(f"[INFO] Blocos: {self.num_blocks:,} x {block_size} bytes")

    def analyze(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Analisa entropia de toda a ROM

        Returns:
            Tupla (entropy_map, type_map)
            - entropy_map: Array de valores de entropia (float)
            - type_map: Array de tipos (int 0-8)
        """
        import time
        start_time = time.time()

        if self.verbose:
            print(f"\n[INFO] Analisando entropia...")

        # Reshape ROM em blocos (padding com zeros se necess√°rio)
        padded_size = self.num_blocks * self.block_size
        if padded_size > self.rom_size:
            padded_data = np.zeros(padded_size, dtype=np.uint8)
            padded_data[:self.rom_size] = self.rom_data
        else:
            padded_data = self.rom_data

        # Reshape em matriz de blocos (VETORIZADO)
        blocks_matrix = padded_data[:self.num_blocks * self.block_size].reshape(
            self.num_blocks, self.block_size
        )

        # Calcula entropia de todos os blocos de uma vez (ULTRA-R√ÅPIDO)
        self.entropy_map = self._calculate_entropy_vectorized(blocks_matrix)

        # Classifica blocos
        self.type_map = self._classify_blocks(self.entropy_map)

        # Cria objetos EntropyBlock
        self.blocks = []
        for i in range(self.num_blocks):
            offset = i * self.block_size
            if offset >= self.rom_size:
                break

            # Pega bloco original (sem padding)
            end_offset = min(offset + self.block_size, self.rom_size)
            block_data = self.rom_data[offset:end_offset]

            # Calcula distribui√ß√£o de bytes
            unique, counts = np.unique(block_data, return_counts=True)
            byte_dist = dict(zip(unique.tolist(), counts.tolist()))

            block = EntropyBlock(
                offset=offset,
                size=len(block_data),
                entropy=float(self.entropy_map[i]),
                block_type=BlockType(int(self.type_map[i])),
                byte_distribution=byte_dist
            )
            self.blocks.append(block)

        elapsed = time.time() - start_time

        if self.verbose:
            print(f"[OK] An√°lise conclu√≠da em {elapsed:.3f}s")
            print(f"[INFO] Performance: {self.rom_size / elapsed / 1024 / 1024:.1f} MB/s")
            self._print_statistics()

        return self.entropy_map, self.type_map

    def _calculate_entropy_vectorized(self, blocks_matrix: np.ndarray) -> np.ndarray:
        """
        Calcula entropia de Shannon para todos os blocos (VETORIZADO)

        Entropia de Shannon:
        H(X) = -Œ£ P(x) * log2(P(x))

        Onde P(x) √© a probabilidade de cada byte (0-255)

        Args:
            blocks_matrix: Matriz (num_blocks, block_size)

        Returns:
            Array de entropias (num_blocks,)
        """
        num_blocks = blocks_matrix.shape[0]
        entropies = np.zeros(num_blocks, dtype=np.float32)

        # Processa cada bloco (ainda r√°pido pois usa NumPy internamente)
        for i in range(num_blocks):
            block = blocks_matrix[i]

            # Conta frequ√™ncia de cada byte
            unique, counts = np.unique(block, return_counts=True)

            # Calcula probabilidades
            probabilities = counts / len(block)

            # Calcula entropia: -Œ£ P(x) * log2(P(x))
            # Usa log2 porque trabalhamos com bytes (base 2)
            entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # +epsilon para evitar log(0)

            entropies[i] = entropy

        return entropies

    def _classify_blocks(self, entropy_values: np.ndarray) -> np.ndarray:
        """
        Classifica blocos baseado em valores de entropia

        Escala de Entropia (bytes = 8 bits, max te√≥rico = 8.0):
        0.0 - 1.0: EMPTY (zeros/padding)
        1.0 - 2.0: VERY_LOW (dados muito repetitivos)
        2.0 - 3.0: LOW (estruturas simples)
        3.0 - 4.0: TEXT (texto ASCII / tabelas) ‚Üê ALVO PRINCIPAL
        4.0 - 5.0: MIXED_TEXT (texto com dados)
        5.0 - 6.0: CODE (c√≥digo execut√°vel t√≠pico)
        6.0 - 7.0: MIXED_DATA (dados variados)
        7.0 - 7.5: HIGH (dados complexos)
        7.5 - 8.0: COMPRESSED (comprimido/encriptado/aleat√≥rio)

        Args:
            entropy_values: Array de valores de entropia

        Returns:
            Array de tipos (BlockType enum values)
        """
        types = np.zeros_like(entropy_values, dtype=np.uint8)

        # Vetorizado - todas as compara√ß√µes de uma vez
        types[entropy_values < 1.0] = BlockType.EMPTY.value
        types[(entropy_values >= 1.0) & (entropy_values < 2.0)] = BlockType.VERY_LOW.value
        types[(entropy_values >= 2.0) & (entropy_values < 3.0)] = BlockType.LOW.value
        types[(entropy_values >= 3.0) & (entropy_values < 4.0)] = BlockType.TEXT.value
        types[(entropy_values >= 4.0) & (entropy_values < 5.0)] = BlockType.MIXED_TEXT.value
        types[(entropy_values >= 5.0) & (entropy_values < 6.0)] = BlockType.CODE.value
        types[(entropy_values >= 6.0) & (entropy_values < 7.0)] = BlockType.MIXED_DATA.value
        types[(entropy_values >= 7.0) & (entropy_values < 7.5)] = BlockType.HIGH.value
        types[entropy_values >= 7.5] = BlockType.COMPRESSED.value

        return types

    def get_regions(self) -> List[EntropyRegion]:
        """
        Agrupa blocos cont√≠guos do mesmo tipo em regi√µes

        Returns:
            Lista de regi√µes detectadas
        """
        if not self.blocks:
            self.analyze()

        regions = []

        if not self.blocks:
            return regions

        # Inicia primeira regi√£o
        current_type = self.blocks[0].block_type
        region_start = self.blocks[0].offset
        region_blocks = [self.blocks[0]]

        for i in range(1, len(self.blocks)):
            block = self.blocks[i]

            if block.block_type == current_type:
                # Mesma regi√£o
                region_blocks.append(block)
            else:
                # Nova regi√£o - salva anterior
                avg_entropy = np.mean([b.entropy for b in region_blocks])

                regions.append(EntropyRegion(
                    start_offset=region_start,
                    end_offset=region_blocks[-1].offset + region_blocks[-1].size,
                    block_type=current_type,
                    block_count=len(region_blocks),
                    avg_entropy=float(avg_entropy)
                ))

                # Inicia nova regi√£o
                current_type = block.block_type
                region_start = block.offset
                region_blocks = [block]

        # Adiciona √∫ltima regi√£o
        if region_blocks:
            avg_entropy = np.mean([b.entropy for b in region_blocks])
            regions.append(EntropyRegion(
                start_offset=region_start,
                end_offset=region_blocks[-1].offset + region_blocks[-1].size,
                block_type=current_type,
                block_count=len(region_blocks),
                avg_entropy=float(avg_entropy)
            ))

        return regions

    def find_text_regions(self, min_blocks: int = 4) -> List[EntropyRegion]:
        """
        Encontra regi√µes prov√°veis de texto/tabelas

        Args:
            min_blocks: N√∫mero m√≠nimo de blocos consecutivos

        Returns:
            Lista de regi√µes de texto
        """
        regions = self.get_regions()

        text_regions = [
            r for r in regions
            if r.block_type in [BlockType.TEXT, BlockType.MIXED_TEXT]
            and r.block_count >= min_blocks
        ]

        # Ordena por tamanho (maiores primeiro)
        text_regions.sort(key=lambda r: r.size, reverse=True)

        return text_regions

    def get_heatmap_array(self) -> np.ndarray:
        """
        Retorna array de 0-8 para desenhar barra de calor

        Returns:
            Array NumPy com valores 0-8 (BlockType enum values)
        """
        if self.type_map is None:
            self.analyze()

        return self.type_map

    def export_visualization_data(self, output_path: str):
        """
        Exporta dados para visualiza√ß√£o

        Args:
            output_path: Caminho do arquivo JSON
        """
        if not self.blocks:
            self.analyze()

        regions = self.get_regions()
        text_regions = self.find_text_regions()

        data = {
            "rom_file": str(self.rom_path.name),
            "rom_size": int(self.rom_size),
            "block_size": int(self.block_size),
            "num_blocks": int(self.num_blocks),
            "heatmap": self.type_map.tolist(),
            "regions": [
                {
                    "start": f"0x{r.start_offset:X}",
                    "end": f"0x{r.end_offset:X}",
                    "size": r.size,
                    "type": r.block_type.name,
                    "blocks": r.block_count,
                    "entropy": f"{r.avg_entropy:.2f}",
                    "color": r.block_type.get_color(),
                    "description": r.block_type.get_description()
                }
                for r in regions
            ],
            "text_regions": [
                {
                    "start": f"0x{r.start_offset:X}",
                    "end": f"0x{r.end_offset:X}",
                    "size": r.size,
                    "entropy": f"{r.avg_entropy:.2f}"
                }
                for r in text_regions
            ]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)

        if self.verbose:
            print(f"[OK] Visualiza√ß√£o exportada: {output_path}")

    def _print_statistics(self):
        """Imprime estat√≠sticas da an√°lise"""
        if not self.blocks:
            return

        # Conta blocos por tipo
        type_counts = {}
        for block in self.blocks:
            block_type = block.block_type
            type_counts[block_type] = type_counts.get(block_type, 0) + 1

        print("\n" + "="*80)
        print("üìä ESTAT√çSTICAS DE ENTROPIA")
        print("="*80)

        for block_type in BlockType:
            count = type_counts.get(block_type, 0)
            if count > 0:
                percentage = (count / len(self.blocks)) * 100
                size_kb = (count * self.block_size) / 1024
                print(f"  {block_type.get_description():20} | "
                      f"{count:6,} blocos ({percentage:5.1f}%) | "
                      f"{size_kb:8.1f} KB")

        # Mostra regi√µes de texto
        text_regions = self.find_text_regions()
        if text_regions:
            print("\n" + "-"*80)
            print(f"üéØ REGI√ïES DE TEXTO DETECTADAS: {len(text_regions)}")
            print("-"*80)

            for i, region in enumerate(text_regions[:10], 1):
                print(f"  [{i}] 0x{region.start_offset:06X} - 0x{region.end_offset:06X} "
                      f"({region.size:,} bytes, {region.block_count} blocos)")

            if len(text_regions) > 10:
                print(f"  ... (+{len(text_regions) - 10} regi√µes)")

        print("="*80)


# ============================================================================
# EXEMPLO DE USO
# ============================================================================

def main():
    """Exemplo de uso do EntropyAnalyzer"""
    import sys

    print("="*80)
    print("üìä ENTROPY ANALYZER - Raio-X de ROMs")
    print("="*80)
    print()

    if len(sys.argv) < 2:
        print("Uso: python entropy_analyzer.py <rom_path> [block_size]")
        print("\nExemplo:")
        print("  python entropy_analyzer.py game.smc")
        print("  python entropy_analyzer.py game.smc 512")
        return 1

    rom_path = sys.argv[1]
    block_size = int(sys.argv[2]) if len(sys.argv) > 2 else 256

    try:
        # Cria analyzer
        analyzer = EntropyAnalyzer(rom_path, block_size=block_size, verbose=True)

        # Analisa
        entropy_map, type_map = analyzer.analyze()

        # Exporta visualiza√ß√£o
        output_file = f"{Path(rom_path).stem}_entropy.json"
        analyzer.export_visualization_data(output_file)

        print(f"\nüíæ Dados exportados: {output_file}")
        print(f"üìà Array heatmap: {len(type_map):,} valores (0-8)")
        print(f"\n‚úÖ Use o array 'heatmap' para desenhar barra de calor na interface!")

        return 0

    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())